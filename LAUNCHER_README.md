# System Launcher Scripts

This directory contains two launcher scripts to start both the backend and frontend of the Multi-Perspective LLM Ensemble System simultaneously.

## Available Launchers

### 1. Python Launcher (Recommended)
```bash
python start_system.py
```
**Features:**
- âœ… Advanced process management
- âœ… Real-time output monitoring with prefixes
- âœ… Automatic dependency checking
- âœ… Graceful shutdown handling
- âœ… Cross-platform compatibility
- âœ… Colored output and status messages

### 2. Shell Script Launcher (Alternative)
```bash
./start_system.sh
```
**Features:**
- âœ… Fast startup with minimal overhead
- âœ… Colored terminal output
- âœ… Process monitoring
- âœ… Signal handling for clean shutdown
- âœ… Native bash performance
- âš ï¸ Unix/Linux/macOS only

## What the Launchers Do

1. **Validation**: Check that all required files and dependencies exist
2. **Backend Startup**: Start the WebSocket server on `ws://localhost:8001`
3. **Frontend Startup**: Start the Vite development server on `http://localhost:5173`
4. **Monitoring**: Monitor both processes and restart if needed
5. **Cleanup**: Gracefully shutdown both services on Ctrl+C

## System Requirements

### Backend Requirements
- Python 3.8+ with virtual environment at `.venv/`
- All Python dependencies installed (`pip install -r requirements.txt`)
- Valid API keys configured in `config/settings.py`

### Frontend Requirements
- Node.js 16+ and npm
- Frontend dependencies installed (`npm install` in `fontend/` directory)

## Usage Examples

### Quick Start (Python)
```bash
# Make sure you're in the project root
cd /path/to/llm_ensemble_langgraph

# Start both services
python start_system.py
```

### Quick Start (Shell)
```bash
# Make sure you're in the project root
cd /path/to/llm_ensemble_langgraph

# Start both services
./start_system.sh
```

### Expected Output
```
================================================================================
ğŸš€ Multi-Perspective LLM Ensemble System Launcher
================================================================================
ğŸ“ Project root: /path/to/llm_ensemble_langgraph
ğŸ Python virtual env: /path/to/.venv/bin/python
ğŸ”§ Backend script: /path/to/backend_websocket_server.py
ğŸŒ Frontend directory: /path/to/fontend
================================================================================
ğŸš€ Starting Backend WebSocket Server...
âœ… Backend server started successfully
ğŸ¨ Starting Frontend Development Server...
âœ… Frontend server started successfully

================================================================================
ğŸ‰ SYSTEM SUCCESSFULLY STARTED!
================================================================================
ğŸ”§ Backend WebSocket Server: ws://localhost:8001
ğŸŒ Frontend Application: http://localhost:5173
ğŸ“Š Multi-Perspective Analysis: Economic, Environmental, Technological
ğŸ§  Chain of Thought: Universal + Perspective-specific
================================================================================
âš¡ Press Ctrl+C to stop both services
ğŸŒ Open your browser to http://localhost:5173 to use the application
================================================================================
```

## Troubleshooting

### Common Issues

1. **Virtual Environment Not Found**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Frontend Dependencies Missing**
   ```bash
   cd fontend/
   npm install
   ```

3. **API Keys Not Configured**
   - Edit `config/settings.py`
   - Add your Claude, OpenAI, and X.AI API keys

4. **Port Already in Use**
   - Backend: Check if port 8001 is available
   - Frontend: Check if port 5173 is available
   - Kill existing processes: `lsof -ti:8001 | xargs kill -9`

### Manual Startup (If Launchers Fail)

**Terminal 1 - Backend:**
```bash
cd /path/to/llm_ensemble_langgraph
source .venv/bin/activate
python backend_websocket_server.py
```

**Terminal 2 - Frontend:**
```bash
cd /path/to/llm_ensemble_langgraph/fontend
npm run dev
```

## System Architecture

The launchers coordinate these components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    System Launcher                          â”‚
â”‚  (start_system.py or start_system.sh)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                         â”‚
              â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend WebSocket     â”‚   â”‚   Frontend Vite Dev     â”‚
â”‚   Server (Port 8001)    â”‚   â”‚   Server (Port 5173)    â”‚
â”‚                         â”‚   â”‚                         â”‚
â”‚ â€¢ LangGraph Workflow    â”‚   â”‚ â€¢ React + TypeScript    â”‚
â”‚ â€¢ Multi-Perspective     â”‚   â”‚ â€¢ Real-time WebSocket   â”‚
â”‚ â€¢ Chain of Thought      â”‚   â”‚ â€¢ Agent Visualization   â”‚
â”‚ â€¢ Claude/GPT/Grok APIs  â”‚   â”‚ â€¢ Progress Tracking     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Next Steps

After starting the system:

1. Open your browser to `http://localhost:5173`
2. Enter a query in the input field
3. Optionally configure Chain of Thought instructions
4. Click "Analyze" to start the multi-perspective analysis
5. Watch real-time agent outputs and progress
6. Review the comprehensive synthesis and performance metrics

The system will provide:
- Economic perspective analysis
- Environmental perspective analysis  
- Technological perspective analysis
- Baseline comparison
- Judge evaluation and synthesis
- Performance improvement metrics
